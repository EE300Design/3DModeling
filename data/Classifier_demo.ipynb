{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifier_demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NGPqDyopB_wG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from glob import *\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['cylinder','cube']\n",
        "\n",
        "def parse_image(filename):\n",
        "  parts = tf.strings.split(filename, os.sep)\n",
        "  label = parts[-2]\n",
        "\n",
        "  image = tf.io.read_file(filename)\n",
        "  image = tf.io.decode_jpeg(image)\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = tf.image.resize(image, [128, 128])\n",
        "  return image, label\n",
        "\n",
        "def process_path(file_path):\n",
        "  label = tf.strings.split(file_path, os.sep)[-2]\n",
        "  return tf.io.read_file(file_path), label\n",
        "\n",
        "labeled_ds = list_ds.map(process_path)\n",
        "def show(image, label):\n",
        "  plt.figure()\n",
        "  plt.imshow(image[:,:,0], cmap='gray')\n",
        "  plt.title(label.numpy().decode('utf-8'))\n",
        "  plt.axis('off')\n",
        "\n",
        "def parse_image(filename):\n",
        "  parts = tf.strings.split(filename, os.sep)\n",
        "  label = parts[-2]\n",
        "\n",
        "  image = tf.io.read_file(filename)\n",
        "  image = tf.io.decode_jpeg(image)\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  return image, label\n"
      ],
      "metadata": {
        "id": "iiZxyZKHzkuR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import shape\n",
        "list_ds = tf.data.Dataset.list_files(\"/content/drive/MyDrive/Colab Notebooks/data/cubes/*\")\n",
        "\n",
        "# for f in list_ds.take(5):\n",
        "#   print(f.numpy())\n",
        "\n",
        "\n",
        "file_path = next(iter(list_ds))\n",
        "image, label = parse_image(file_path)\n",
        "image\n",
        "show(image, label)\n",
        "\n",
        "image, label = parse_image(\"/content/drive/MyDrive/Colab Notebooks/data/cylinders/cylinder0.png\")\n",
        "tf.print(shape(image))\n",
        "show(image, label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "1HJDBAJZCiyu",
        "outputId": "c633c96e-faf5-43cd-fdfe-49572b152b5a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorShape([300, 300, 1])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 300\n",
        "img_width = 300\n",
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/data\"\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split = .2,\n",
        "    subset=\"training\",\n",
        "    seed = 123,\n",
        "    image_size = (img_height,img_width),\n",
        "    batch_size = batch_size)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5a1QSjudEqv",
        "outputId": "75e42455-f68c-4e1d-b3c0-1e3b58bf49a0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 210 files belonging to 2 classes.\n",
            "Using 168 files for training.\n",
            "Found 210 files belonging to 2 classes.\n",
            "Using 42 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaI_ee0FeXen",
        "outputId": "e892bbbc-750b-4c63-b142-6a19f0e1cd4a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cubes', 'cylinders']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "-tAqM2ZWemeg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = layers.Rescaling(1./255)\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(len(class_names))\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hahQ3O4e-Cu",
        "outputId": "e99699fb-4f38-4539-d671-d674c589ceab"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_3 (Rescaling)     (None, 300, 300, 3)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 300, 300, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 150, 150, 16)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 150, 150, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 75, 75, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 75, 75, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 37, 37, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 87616)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               11214976  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,238,818\n",
            "Trainable params: 11,238,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF1wsYvifpbU",
        "outputId": "6631ec5f-1801-4c13-f258-07dc207ec5d0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 19s 3s/step - loss: 0.7826 - accuracy: 0.8690 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 3.4727e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 15s 2s/step - loss: 1.7633e-04 - accuracy: 1.0000 - val_loss: 3.4472e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 14s 3s/step - loss: 1.1004e-05 - accuracy: 1.0000 - val_loss: 2.8979e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 14s 2s/step - loss: 1.6334e-06 - accuracy: 1.0000 - val_loss: 8.3730e-07 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 14s 3s/step - loss: 5.7902e-07 - accuracy: 1.0000 - val_loss: 4.8819e-07 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 14s 2s/step - loss: 3.9807e-07 - accuracy: 1.0000 - val_loss: 3.5479e-07 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 14s 2s/step - loss: 2.9731e-07 - accuracy: 1.0000 - val_loss: 2.6680e-07 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 14s 2s/step - loss: 2.3842e-07 - accuracy: 1.0000 - val_loss: 2.1855e-07 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 14s 2s/step - loss: 1.9726e-07 - accuracy: 1.0000 - val_loss: 1.8733e-07 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ]
}